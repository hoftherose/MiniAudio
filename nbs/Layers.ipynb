{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#default_exp layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Layers\n",
    "> Important Model Layers for audio related tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from fastai2.basics import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Invertible Conv Layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Invertible1x1Conv(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    The layer outputs both the convolution, and the log determinant\n",
    "    of its weight matrix.  If reverse=True it does convolution with\n",
    "    inverse\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, c):\n",
    "        super(Invertible1x1Conv, self).__init__()\n",
    "        self.conv = torch.nn.Conv1d(c, c, kernel_size=1, stride=1, padding=0,\n",
    "                                    bias=False)\n",
    "\n",
    "        # Sample a random orthonormal matrix to initialize weights\n",
    "        W = torch.qr(torch.FloatTensor(c, c).normal_())[0]\n",
    "\n",
    "        # Ensure determinant is 1.0 not -1.0\n",
    "        if torch.det(W) < 0:\n",
    "            W[:, 0] = -1 * W[:, 0]\n",
    "        W = W.view(c, c, 1)\n",
    "        self.conv.weight.data = W\n",
    "\n",
    "    def forward(self, z, reverse=False):\n",
    "        # shape\n",
    "        batch_size, group_size, n_of_groups = z.size()\n",
    "\n",
    "        W = self.conv.weight.squeeze()\n",
    "\n",
    "        if reverse:\n",
    "            if not hasattr(self, 'W_inverse'):\n",
    "                # Reverse computation\n",
    "                W_inverse = W.inverse()\n",
    "                W_inverse = Variable(W_inverse[..., None])\n",
    "                if z.type() == 'torch.cuda.HalfTensor' or z.type() == 'torch.HalfTensor':\n",
    "                    W_inverse = W_inverse.half()\n",
    "                self.W_inverse = W_inverse\n",
    "            z = F.conv1d(z, self.W_inverse, bias=None, stride=1, padding=0)\n",
    "            return z\n",
    "        else:\n",
    "            # Forward computation\n",
    "            log_det_W = torch.logdet(W)\n",
    "            log_det_W = batch_size * n_of_groups * log_det_W\n",
    "            if z.dtype == torch.float16:\n",
    "                z = self.conv(z.float()).half()\n",
    "            else:\n",
    "                z = self.conv(z)\n",
    "            return z, log_det_W"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_layer = Invertible1x1Conv(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = torch.tensor([[[1.],[2.],[3.]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[-1.6221],\n",
       "          [-3.3548],\n",
       "          [-0.3380]]], grad_fn=<SqueezeBackward1>),\n",
       " tensor(-1.1921e-07, grad_fn=<MulBackward0>))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = inv_layer(inp)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 1])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WaveNet Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "@delegates(torch.nn.Conv1d)\n",
    "def WeightedConv1d(in_channels, out_channels, kernel_size, **kwargs):\n",
    "    layer = nn.Conv1d(in_channels, out_channels, kernel_size, **kwargs)\n",
    "    return torch.nn.utils.weight_norm(layer, name='weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class WaveNetLayer(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Traditional WaveNet Layer which outputs both the residual value and the output.\n",
    "    \"\"\"\n",
    "    def __init__(self, n_mel_channels, kernel_size, dilation, padding):\n",
    "        super(WaveNetLayer, self).__init__()\n",
    "        self.SigmDilation = WeightedConv1d(n_mel_channels, n_mel_channels//2, kernel_size,\n",
    "                                           dilation=dilation, padding=padding)\n",
    "        self.TanhDilation = WeightedConv1d(n_mel_channels, n_mel_channels//2, kernel_size,\n",
    "                                           dilation=dilation, padding=padding)\n",
    "        self.ResLinear = torch.nn.Conv1d(n_mel_channels//2,n_mel_channels, 1, stride=1)\n",
    "        self.OutLinear = torch.nn.Conv1d(n_mel_channels//2,n_mel_channels, 1, stride=1)\n",
    "    def forward(self, x):\n",
    "        sigm_output = torch.nn.Sigmoid()(self.SigmDilation(x))\n",
    "        tanh_output = torch.nn.Tanh()(self.TanhDilation(x))\n",
    "        prod = torch.mul(sigm_output, tanh_output)\n",
    "        out = self.OutLinear(prod)\n",
    "        res = self.ResLinear(prod)+x\n",
    "        return out, res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class WaveNet(torch.nn.Module):\n",
    "    def __init__(self, n_mel_channels, precision, n_layers, kernel_size, sample_rate, time):\n",
    "        super(WaveNet, self).__init__()\n",
    "        store_attr(self, 'n_mel_channels, precision, n_layers, kernel_size, sample_rate, time')\n",
    "        self.upsample = torch.nn.ConvTranspose1d(n_mel_channels,n_mel_channels,1024, stride=512)\n",
    "        self.WaveNetLayers = torch.nn.ModuleList()\n",
    "        for i in range(self.n_layers):\n",
    "            dilation = 2 ** i\n",
    "            padding = int((kernel_size * dilation - dilation) / 2)\n",
    "            self.WaveNetLayers.append(WaveNetLayer(n_mel_channels, kernel_size, dilation, padding))\n",
    "        self.end = torch.nn.Sequential(torch.nn.ReLU(),torch.nn.Conv1d(n_mel_channels,n_mel_channels*2, 1),\n",
    "                                       torch.nn.ReLU(),torch.nn.Conv1d(n_mel_channels*2,precision, 1),\n",
    "                                       torch.nn.Softmax(dim=1))\n",
    "\n",
    "    def forward(self, spec):\n",
    "        x = self.upsample(spec)[:,:,:self.sample_rate*self.time]\n",
    "        for i in range(self.n_layers):\n",
    "            out, x = self.WaveNetLayers[i](x)\n",
    "            if i == 0: output = out\n",
    "            else:      output = out+output\n",
    "        return self.end(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# U-Net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic U-Net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class conv_block(nn.Module):\n",
    "    \"\"\"\n",
    "    | Conv2d, BatchNorm, ReLU | -> | Conv2d BatchNorm ReLU | ->\n",
    "    \"\"\"\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(conv_block, self).__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, kernel_size=3, stride=1, padding=1, bias=True),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_ch, out_ch, kernel_size=3, stride=1, padding=1, bias=True),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True))\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class up_conv(nn.Module):\n",
    "    \"\"\"\n",
    "    | Upsample | -> | Conv2d BatchNorm ReLU | ->\n",
    "    \"\"\"\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(up_conv, self).__init__()\n",
    "        self.up = nn.Sequential(\n",
    "            nn.Upsample(scale_factor=2),\n",
    "            nn.Conv2d(in_ch, out_ch, kernel_size=3, stride=1, padding=1, bias=True),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.up(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![U-Net implementation from https://github.com/bigmb/Unet-Segmentation-Pytorch-Nest-of-Unets](https://raw.githubusercontent.com/bigmb/Unet-Segmentation-Pytorch-Nest-of-Unets/master/images/unet1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class U_Net(nn.Module):\n",
    "    \"\"\"\n",
    "    UNet - Basic Implementation\n",
    "    Paper : https://arxiv.org/abs/1505.04597\n",
    "    \"\"\"\n",
    "    def __init__(self, in_ch=3, out_ch=1):\n",
    "        super(U_Net, self).__init__()\n",
    "\n",
    "        n1 = 64\n",
    "        filters = [n1, n1 * 2, n1 * 4, n1 * 8, n1 * 16]\n",
    "        \n",
    "        self.Maxpool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.Maxpool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.Maxpool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.Maxpool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.Conv1 = conv_block(in_ch, filters[0])\n",
    "        self.Conv2 = conv_block(filters[0], filters[1])\n",
    "        self.Conv3 = conv_block(filters[1], filters[2])\n",
    "        self.Conv4 = conv_block(filters[2], filters[3])\n",
    "        self.Conv5 = conv_block(filters[3], filters[4])\n",
    "\n",
    "        self.Up5 = up_conv(filters[4], filters[3])\n",
    "        self.Up_conv5 = conv_block(filters[4], filters[3])\n",
    "\n",
    "        self.Up4 = up_conv(filters[3], filters[2])\n",
    "        self.Up_conv4 = conv_block(filters[3], filters[2])\n",
    "\n",
    "        self.Up3 = up_conv(filters[2], filters[1])\n",
    "        self.Up_conv3 = conv_block(filters[2], filters[1])\n",
    "\n",
    "        self.Up2 = up_conv(filters[1], filters[0])\n",
    "        self.Up_conv2 = conv_block(filters[1], filters[0])\n",
    "\n",
    "        self.Conv = nn.Conv2d(filters[0], out_ch, kernel_size=1, stride=1, padding=0)\n",
    "\n",
    "       # self.active = torch.nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        e1 = self.Conv1(x)\n",
    "\n",
    "        e2 = self.Maxpool1(e1)\n",
    "        e2 = self.Conv2(e2)\n",
    "\n",
    "        e3 = self.Maxpool2(e2)\n",
    "        e3 = self.Conv3(e3)\n",
    "\n",
    "        e4 = self.Maxpool3(e3)\n",
    "        e4 = self.Conv4(e4)\n",
    "\n",
    "        e5 = self.Maxpool4(e4)\n",
    "        e5 = self.Conv5(e5)\n",
    "\n",
    "        d5 = self.Up5(e5)\n",
    "        d5 = torch.cat((e4, d5), dim=1)\n",
    "\n",
    "        d5 = self.Up_conv5(d5)\n",
    "\n",
    "        d4 = self.Up4(d5)\n",
    "        d4 = torch.cat((e3, d4), dim=1)\n",
    "        d4 = self.Up_conv4(d4)\n",
    "\n",
    "        d3 = self.Up3(d4)\n",
    "        d3 = torch.cat((e2, d3), dim=1)\n",
    "        d3 = self.Up_conv3(d3)\n",
    "\n",
    "        d2 = self.Up2(d3)\n",
    "        d2 = torch.cat((e1, d2), dim=1)\n",
    "        d2 = self.Up_conv2(d2)\n",
    "\n",
    "        out = self.Conv(d2)\n",
    "\n",
    "        #d1 = self.active(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recurrent U-Net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Recurrent_block(nn.Module):\n",
    "    \"\"\"\n",
    "    Recurrent Block for R2Unet_CNN\n",
    "    \"\"\"\n",
    "    def __init__(self, out_ch, t=2):\n",
    "        super(Recurrent_block, self).__init__()\n",
    "\n",
    "        self.t = t\n",
    "        self.out_ch = out_ch\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(out_ch, out_ch, kernel_size=3, stride=1, padding=1, bias=True),\n",
    "            nn.BatchNorm2d(out_ch),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        for i in range(self.t):\n",
    "            if i == 0:\n",
    "                x = self.conv(x)\n",
    "            out = self.conv(x + x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class RRCNN_block(nn.Module):\n",
    "    \"\"\"\n",
    "    Recurrent Residual Convolutional Neural Network Block\n",
    "    \"\"\"\n",
    "    def __init__(self, in_ch, out_ch, t=2):\n",
    "        super(RRCNN_block, self).__init__()\n",
    "\n",
    "        self.RCNN = nn.Sequential(\n",
    "            Recurrent_block(out_ch, t=t),\n",
    "            Recurrent_block(out_ch, t=t)\n",
    "        )\n",
    "        self.Conv = nn.Conv2d(in_ch, out_ch, kernel_size=1, stride=1, padding=0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.Conv(x)\n",
    "        x2 = self.RCNN(x1)\n",
    "        out = x1 + x2\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Recurrent U-Net implementation from https://github.com/bigmb/Unet-Segmentation-Pytorch-Nest-of-Unets](https://raw.githubusercontent.com/bigmb/Unet-Segmentation-Pytorch-Nest-of-Unets/master/images/r2unet.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class R2U_Net(nn.Module):\n",
    "    \"\"\"\n",
    "    R2U-Unet implementation\n",
    "    Paper: https://arxiv.org/abs/1802.06955\n",
    "    \"\"\"\n",
    "    def __init__(self, img_ch=3, output_ch=1, t=2):\n",
    "        super(R2U_Net, self).__init__()\n",
    "\n",
    "        n1 = 64\n",
    "        filters = [n1, n1 * 2, n1 * 4, n1 * 8, n1 * 16]\n",
    "\n",
    "        self.Maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.Maxpool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.Maxpool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.Maxpool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.Upsample = nn.Upsample(scale_factor=2)\n",
    "\n",
    "        self.RRCNN1 = RRCNN_block(img_ch, filters[0], t=t)\n",
    "\n",
    "        self.RRCNN2 = RRCNN_block(filters[0], filters[1], t=t)\n",
    "\n",
    "        self.RRCNN3 = RRCNN_block(filters[1], filters[2], t=t)\n",
    "\n",
    "        self.RRCNN4 = RRCNN_block(filters[2], filters[3], t=t)\n",
    "\n",
    "        self.RRCNN5 = RRCNN_block(filters[3], filters[4], t=t)\n",
    "\n",
    "        self.Up5 = up_conv(filters[4], filters[3])\n",
    "        self.Up_RRCNN5 = RRCNN_block(filters[4], filters[3], t=t)\n",
    "\n",
    "        self.Up4 = up_conv(filters[3], filters[2])\n",
    "        self.Up_RRCNN4 = RRCNN_block(filters[3], filters[2], t=t)\n",
    "\n",
    "        self.Up3 = up_conv(filters[2], filters[1])\n",
    "        self.Up_RRCNN3 = RRCNN_block(filters[2], filters[1], t=t)\n",
    "\n",
    "        self.Up2 = up_conv(filters[1], filters[0])\n",
    "        self.Up_RRCNN2 = RRCNN_block(filters[1], filters[0], t=t)\n",
    "\n",
    "        self.Conv = nn.Conv2d(filters[0], output_ch, kernel_size=1, stride=1, padding=0)\n",
    "\n",
    "       # self.active = torch.nn.Sigmoid()\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        e1 = self.RRCNN1(x)\n",
    "\n",
    "        e2 = self.Maxpool(e1)\n",
    "        e2 = self.RRCNN2(e2)\n",
    "\n",
    "        e3 = self.Maxpool1(e2)\n",
    "        e3 = self.RRCNN3(e3)\n",
    "\n",
    "        e4 = self.Maxpool2(e3)\n",
    "        e4 = self.RRCNN4(e4)\n",
    "\n",
    "        e5 = self.Maxpool3(e4)\n",
    "        e5 = self.RRCNN5(e5)\n",
    "\n",
    "        d5 = self.Up5(e5)\n",
    "        d5 = torch.cat((e4, d5), dim=1)\n",
    "        d5 = self.Up_RRCNN5(d5)\n",
    "\n",
    "        d4 = self.Up4(d5)\n",
    "        d4 = torch.cat((e3, d4), dim=1)\n",
    "        d4 = self.Up_RRCNN4(d4)\n",
    "\n",
    "        d3 = self.Up3(d4)\n",
    "        d3 = torch.cat((e2, d3), dim=1)\n",
    "        d3 = self.Up_RRCNN3(d3)\n",
    "\n",
    "        d2 = self.Up2(d3)\n",
    "        d2 = torch.cat((e1, d2), dim=1)\n",
    "        d2 = self.Up_RRCNN2(d2)\n",
    "\n",
    "        out = self.Conv(d2)\n",
    "\n",
    "      # out = self.active(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attention U-Net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Attention_block(nn.Module):\n",
    "    \"\"\"\n",
    "    Attention Block\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, F_g, F_l, F_int):\n",
    "        super(Attention_block, self).__init__()\n",
    "\n",
    "        self.W_g = nn.Sequential(\n",
    "            nn.Conv2d(F_l, F_int, kernel_size=1, stride=1, padding=0, bias=True),\n",
    "            nn.BatchNorm2d(F_int)\n",
    "        )\n",
    "\n",
    "        self.W_x = nn.Sequential(\n",
    "            nn.Conv2d(F_g, F_int, kernel_size=1, stride=1, padding=0, bias=True),\n",
    "            nn.BatchNorm2d(F_int)\n",
    "        )\n",
    "\n",
    "        self.psi = nn.Sequential(\n",
    "            nn.Conv2d(F_int, 1, kernel_size=1, stride=1, padding=0, bias=True),\n",
    "            nn.BatchNorm2d(1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, g, x):\n",
    "        g1 = self.W_g(g)\n",
    "        x1 = self.W_x(x)\n",
    "        psi = self.relu(g1 + x1)\n",
    "        psi = self.psi(psi)\n",
    "        out = x * psi\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Attention U-Net implementation from https://github.com/bigmb/Unet-Segmentation-Pytorch-Nest-of-Unets](https://raw.githubusercontent.com/bigmb/Unet-Segmentation-Pytorch-Nest-of-Unets/master/images/att-unet.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class AttU_Net(nn.Module):\n",
    "    \"\"\"\n",
    "    Attention Unet implementation\n",
    "    Paper: https://arxiv.org/abs/1804.03999\n",
    "    \"\"\"\n",
    "    def __init__(self, img_ch=3, output_ch=1):\n",
    "        super(AttU_Net, self).__init__()\n",
    "\n",
    "        n1 = 64\n",
    "        filters = [n1, n1 * 2, n1 * 4, n1 * 8, n1 * 16]\n",
    "\n",
    "        self.Maxpool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.Maxpool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.Maxpool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.Maxpool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.Conv1 = conv_block(img_ch, filters[0])\n",
    "        self.Conv2 = conv_block(filters[0], filters[1])\n",
    "        self.Conv3 = conv_block(filters[1], filters[2])\n",
    "        self.Conv4 = conv_block(filters[2], filters[3])\n",
    "        self.Conv5 = conv_block(filters[3], filters[4])\n",
    "\n",
    "        self.Up5 = up_conv(filters[4], filters[3])\n",
    "        self.Att5 = Attention_block(F_g=filters[3], F_l=filters[3], F_int=filters[2])\n",
    "        self.Up_conv5 = conv_block(filters[4], filters[3])\n",
    "\n",
    "        self.Up4 = up_conv(filters[3], filters[2])\n",
    "        self.Att4 = Attention_block(F_g=filters[2], F_l=filters[2], F_int=filters[1])\n",
    "        self.Up_conv4 = conv_block(filters[3], filters[2])\n",
    "\n",
    "        self.Up3 = up_conv(filters[2], filters[1])\n",
    "        self.Att3 = Attention_block(F_g=filters[1], F_l=filters[1], F_int=filters[0])\n",
    "        self.Up_conv3 = conv_block(filters[2], filters[1])\n",
    "\n",
    "        self.Up2 = up_conv(filters[1], filters[0])\n",
    "        self.Att2 = Attention_block(F_g=filters[0], F_l=filters[0], F_int=32)\n",
    "        self.Up_conv2 = conv_block(filters[1], filters[0])\n",
    "\n",
    "        self.Conv = nn.Conv2d(filters[0], output_ch, kernel_size=1, stride=1, padding=0)\n",
    "\n",
    "        #self.active = torch.nn.Sigmoid()\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        e1 = self.Conv1(x)\n",
    "\n",
    "        e2 = self.Maxpool1(e1)\n",
    "        e2 = self.Conv2(e2)\n",
    "\n",
    "        e3 = self.Maxpool2(e2)\n",
    "        e3 = self.Conv3(e3)\n",
    "\n",
    "        e4 = self.Maxpool3(e3)\n",
    "        e4 = self.Conv4(e4)\n",
    "\n",
    "        e5 = self.Maxpool4(e4)\n",
    "        e5 = self.Conv5(e5)\n",
    "\n",
    "        #print(x5.shape)\n",
    "        d5 = self.Up5(e5)\n",
    "        #print(d5.shape)\n",
    "        x4 = self.Att5(g=d5, x=e4)\n",
    "        d5 = torch.cat((x4, d5), dim=1)\n",
    "        d5 = self.Up_conv5(d5)\n",
    "\n",
    "        d4 = self.Up4(d5)\n",
    "        x3 = self.Att4(g=d4, x=e3)\n",
    "        d4 = torch.cat((x3, d4), dim=1)\n",
    "        d4 = self.Up_conv4(d4)\n",
    "\n",
    "        d3 = self.Up3(d4)\n",
    "        x2 = self.Att3(g=d3, x=e2)\n",
    "        d3 = torch.cat((x2, d3), dim=1)\n",
    "        d3 = self.Up_conv3(d3)\n",
    "\n",
    "        d2 = self.Up2(d3)\n",
    "        x1 = self.Att2(g=d2, x=e1)\n",
    "        d2 = torch.cat((x1, d2), dim=1)\n",
    "        d2 = self.Up_conv2(d2)\n",
    "\n",
    "        out = self.Conv(d2)\n",
    "\n",
    "      #  out = self.active(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attention and Recurrent U-Net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Recurrent Attention U-Net implementation from https://github.com/bigmb/Unet-Segmentation-Pytorch-Nest-of-Unets](https://raw.githubusercontent.com/bigmb/Unet-Segmentation-Pytorch-Nest-of-Unets/master/images/att-r2u.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class R2AttU_Net(nn.Module):\n",
    "    \"\"\"\n",
    "    Residual Recuurent Block with attention Unet\n",
    "    Implementation : https://github.com/LeeJunHyun/Image_Segmentation\n",
    "    \"\"\"\n",
    "    def __init__(self, in_ch=3, out_ch=1, t=2):\n",
    "        super(R2AttU_Net, self).__init__()\n",
    "\n",
    "        n1 = 64\n",
    "        filters = [n1, n1 * 2, n1 * 4, n1 * 8, n1 * 16]\n",
    "\n",
    "        self.Maxpool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.Maxpool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.Maxpool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.Maxpool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.RRCNN1 = RRCNN_block(in_ch, filters[0], t=t)\n",
    "        self.RRCNN2 = RRCNN_block(filters[0], filters[1], t=t)\n",
    "        self.RRCNN3 = RRCNN_block(filters[1], filters[2], t=t)\n",
    "        self.RRCNN4 = RRCNN_block(filters[2], filters[3], t=t)\n",
    "        self.RRCNN5 = RRCNN_block(filters[3], filters[4], t=t)\n",
    "\n",
    "        self.Up5 = up_conv(filters[4], filters[3])\n",
    "        self.Att5 = Attention_block(F_g=filters[3], F_l=filters[3], F_int=filters[2])\n",
    "        self.Up_RRCNN5 = RRCNN_block(filters[4], filters[3], t=t)\n",
    "\n",
    "        self.Up4 = up_conv(filters[3], filters[2])\n",
    "        self.Att4 = Attention_block(F_g=filters[2], F_l=filters[2], F_int=filters[1])\n",
    "        self.Up_RRCNN4 = RRCNN_block(filters[3], filters[2], t=t)\n",
    "\n",
    "        self.Up3 = up_conv(filters[2], filters[1])\n",
    "        self.Att3 = Attention_block(F_g=filters[1], F_l=filters[1], F_int=filters[0])\n",
    "        self.Up_RRCNN3 = RRCNN_block(filters[2], filters[1], t=t)\n",
    "\n",
    "        self.Up2 = up_conv(filters[1], filters[0])\n",
    "        self.Att2 = Attention_block(F_g=filters[0], F_l=filters[0], F_int=32)\n",
    "        self.Up_RRCNN2 = RRCNN_block(filters[1], filters[0], t=t)\n",
    "\n",
    "        self.Conv = nn.Conv2d(filters[0], out_ch, kernel_size=1, stride=1, padding=0)\n",
    "\n",
    "       # self.active = torch.nn.Sigmoid()\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        e1 = self.RRCNN1(x)\n",
    "\n",
    "        e2 = self.Maxpool1(e1)\n",
    "        e2 = self.RRCNN2(e2)\n",
    "\n",
    "        e3 = self.Maxpool2(e2)\n",
    "        e3 = self.RRCNN3(e3)\n",
    "\n",
    "        e4 = self.Maxpool3(e3)\n",
    "        e4 = self.RRCNN4(e4)\n",
    "\n",
    "        e5 = self.Maxpool4(e4)\n",
    "        e5 = self.RRCNN5(e5)\n",
    "\n",
    "        d5 = self.Up5(e5)\n",
    "        e4 = self.Att5(g=d5, x=e4)\n",
    "        d5 = torch.cat((e4, d5), dim=1)\n",
    "        d5 = self.Up_RRCNN5(d5)\n",
    "\n",
    "        d4 = self.Up4(d5)\n",
    "        e3 = self.Att4(g=d4, x=e3)\n",
    "        d4 = torch.cat((e3, d4), dim=1)\n",
    "        d4 = self.Up_RRCNN4(d4)\n",
    "\n",
    "        d3 = self.Up3(d4)\n",
    "        e2 = self.Att3(g=d3, x=e2)\n",
    "        d3 = torch.cat((e2, d3), dim=1)\n",
    "        d3 = self.Up_RRCNN3(d3)\n",
    "\n",
    "        d2 = self.Up2(d3)\n",
    "        e1 = self.Att2(g=d2, x=e1)\n",
    "        d2 = torch.cat((e1, d2), dim=1)\n",
    "        d2 = self.Up_RRCNN2(d2)\n",
    "\n",
    "        out = self.Conv(d2)\n",
    "\n",
    "      #  out = self.active(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted Layers.ipynb.\n"
     ]
    }
   ],
   "source": [
    "#hide\n",
    "from nbdev.export import notebook2script\n",
    "notebook2script(fname=\"Layers.ipynb\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
